{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path as P\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "if 'Demo scripts' in os.getcwd(): os.chdir('..')  # change to main directory\n",
    "print('Current directory: {}'.format( os.getcwd() ))\n",
    "\n",
    "\n",
    "#CaImAn stuff\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.visualization import inspect_correlation_pnr, nb_inspect_correlation_pnr\n",
    "\n",
    "\n",
    "# CASCADE stuff\n",
    "# import glob\n",
    "# import scipy.io as sio\n",
    "# import ruamel.yaml as yaml\n",
    "\n",
    "# from cascade2p import cascade\n",
    "# from cascade2p.utils import plot_dFF_traces, plot_noise_level_distribution, plot_noise_matched_ground_truth\n",
    "# from cascade2p import checks\n",
    "\n",
    "# checks.check_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"New_Analysis_Pipeline_Test/Test_Data/Raw_Data/wfC318_2016_10_18/recording_20161018_155817.hdf5\"\n",
    "# path = input(\"Enter file path: \\n/home/ar4210/engram/anole/Mouse/\")\n",
    "full_data_dir = f\"/home/ar4210/engram/anole/Mouse/{path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.path.exists(full_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = P(full_data_dir)\n",
    "\n",
    "home_parts = path.parts[:3]\n",
    "engram_dir_parts = path.parts[:10]\n",
    "\n",
    "home = P(*home_parts)\n",
    "engram_path = P(*engram_dir_parts)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "fstem = path.stem # file name without extension\n",
    "extension = path.suffix # .tif, .hdf5, etc.\n",
    "fname = path.name # fstem + extension\n",
    "\n",
    "storage_folder = path.parts[9]\n",
    "\n",
    "print(home)\n",
    "print(engram_path)\n",
    "print(fstem, extension, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination directories\n",
    "destination_dir     = os.path.join(cwd, \"collected_data\")\n",
    "traces_dir          = os.path.join(destination_dir, \"Traces\")\n",
    "inferred_spikes_dir = os.path.join(destination_dir, \"InferredSpikes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaImAn STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [f\"{full_data_dir}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoCorr Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frate = 20                       # movie frame rate\n",
    "decay_time = 0.4                 # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = True         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (5, 5)      # maximum allowed rigid shift\n",
    "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)      # overlap between pathes (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': f[0],\n",
    "    'fr': frate,\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan,\n",
    "    'var_name_hdf5':'images'\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform MoCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if motion_correct:\n",
    "    # do motion correction rigid\n",
    "    mc = MotionCorrect(f[0], dview=dview, var_name_hdf5 = 'images',**opts.get_group('motion'))\n",
    "    mc.motion_correct(save_movie=True)\n",
    "    f_mc = mc.fname_tot_els if pw_rigid else mc.fname_tot_rig\n",
    "    if pw_rigid:\n",
    "        bord_px = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "    else:\n",
    "        bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
    "#         plt.subplot(1, 2, 1); plt.imshow(mc.total_template_rig)  # % plot template\n",
    "#         plt.subplot(1, 2, 2); plt.plot(mc.shifts_rig)  # % plot rigid shifts\n",
    "#         plt.legend(['x shifts', 'y shifts'])\n",
    "#         plt.xlabel('frames')\n",
    "#         plt.ylabel('pixels')\n",
    "\n",
    "    bord_px = 0 if border_nan is 'copy' else bord_px\n",
    "    f_new = cm.save_memmap(f_mc, base_name='memmap_', order='C',\n",
    "                               border_to_0=bord_px)\n",
    "else:  # if no motion correction just memory map the file\n",
    "    f_new = cm.save_memmap(f, base_name='memmap_',\n",
    "                               order='C', border_to_0=0, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load memmap'd file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr, dims, T = cm.load_memmap(f_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNMF-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for CNMF-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "p = 1               # order of the autoregressive system\n",
    "K = None            # upper bound on number of components per patch, in general None\n",
    "gSig = (3, 3)       # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "gSiz = (13, 13)     # average diameter of a neuron, in general 4*gSig+1\n",
    "Ain = None          # possibility to seed with predetermined binary masks\n",
    "merge_thr = .7      # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
    "#                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
    "tsub = 2            # downsampling factor in time for initialization,\n",
    "#                     increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization,\n",
    "#                     increase if you have memory problems\n",
    "#                     you can pass them here as boolean vectors\n",
    "low_rank_background = None  # None leaves background of each patch intact,\n",
    "#                     True performs global low-rank approximation if gnb>0\n",
    "gnb = 0             # number of background components (rank) if positive,\n",
    "#                     else exact ring model with following settings\n",
    "#                         gnb= 0: Return background as b and W\n",
    "#                         gnb=-1: Return full rank background B\n",
    "#                         gnb<-1: Don't return background\n",
    "nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
    "#                     else it is set automatically\n",
    "min_corr = .8       # min peak value from correlation image\n",
    "min_pnr = 10        # min peak to noise ration from PNR image\n",
    "ssub_B = 2          # additional downsampling factor in space for background\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
    "\n",
    "\n",
    "opts = params.CNMFParams(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "                                'K': K,\n",
    "                                'gSig': gSig,\n",
    "                                'gSiz': gSiz,\n",
    "                                'merge_thr': merge_thr,\n",
    "                                'p': p,\n",
    "                                'tsub': tsub,\n",
    "                                'ssub': ssub,\n",
    "                                'rf': rf,\n",
    "                                'stride': stride_cnmf,\n",
    "                                'only_init': True,    # set it to True to run CNMF-E\n",
    "                                'nb': gnb,\n",
    "                                'nb_patch': nb_patch,\n",
    "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                'low_rank_background': low_rank_background,\n",
    "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
    "                                'min_corr': min_corr,\n",
    "                                'min_pnr': min_pnr,\n",
    "                                'normalize_init': False,               # just leave as is\n",
    "                                'center_psf': True,                    # leave as is for 1 photon\n",
    "                                'ssub_B': ssub_B,\n",
    "                                'ring_size_factor': ring_size_factor,\n",
    "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "                                'border_pix': 0})                # number of pixels to not consider in the borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_filter, pnr = cm.summary_images.correlation_pnr(images[::5], gSig=gSig[0], swap_dim=False)\n",
    "nb_inspect_correlation_pnr(cn_filter, pnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform CNMF-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
    "cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "min_SNR = 3            # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.85    # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worst quality)\n",
    "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
    "                           'rval_thr': r_values_min,\n",
    "                           'use_cnn': False})\n",
    "estimates_object = cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "\n",
    "print(' ***** ')\n",
    "print('Number of total components: ', len(cnm.estimates.C))\n",
    "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnm.estimates.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit Data to full FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cnm2 = cnm.refit(images, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimates_object_2 = cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)\n",
    "\n",
    "# print(' ***** ')\n",
    "# print('Number of total components: ', len(cnm2.estimates.C))\n",
    "# print('Number of accepted components: ', len(cnm2.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASCADE STEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Calcium Traces from CaImAn as *.npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"Ca_Traces_{fstem}\", estimates_object.C[cnm.estimates.idx_components])\n",
    "# np.save(f\"Ca_Traces_{fstem}_2\", estimates_object.C[int(len(estimates_object.C / 2)):])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to load in *.npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_neurons_x_time(file_path):\n",
    "    \"\"\"Custom method to load data as 2d array with shape (neurons, nr_timepoints)\"\"\"\n",
    "    \n",
    "    if file_path.endswith('.mat'):\n",
    "        traces = sio.loadmat(file_path)['dF_traces']\n",
    "\n",
    "    elif file_path.endswith('.npy'):\n",
    "        traces = np.load(file_path, allow_pickle=True)\n",
    "        # if saved data was a dictionary packed into a numpy array (MATLAB style): unpack\n",
    "        if traces.shape == ():\n",
    "            traces = traces.item()['dF_traces']\n",
    "    else:\n",
    "        raise Exception('This function only supports .mat or .npy files.')\n",
    "    \n",
    "    # do here transposing or percent to numeric calculation if necessary\n",
    "    # traces = traces.T\n",
    "    # traces = traces / 100\n",
    "    \n",
    "    return traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in calcium traces, plot noise level distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = f'Ca_Traces_{fstem}.npy'\n",
    "\n",
    "traces = load_neurons_x_time( example_file )\n",
    "frame_rate = 20\n",
    "\n",
    "\n",
    "print('Number of neurons in dataset:', traces.shape[0])\n",
    "print('Number of timepoints in dataset:', traces.shape[1])\n",
    "\n",
    "# interactive plotting\n",
    "# %matplotlib notebook\n",
    "\n",
    "noise_levels = plot_noise_level_distribution(traces,frame_rate)\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "# np.random.seed(3452)\n",
    "# neuron_indices = np.random.randint(traces.shape[0], size=10)\n",
    "# plot_dFF_traces(traces,neuron_indices,frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available models from CASCADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade.download_model( 'update_models',verbose = 1)\n",
    "\n",
    "yaml_file = open('Pretrained_models/available_models.yaml')\n",
    "X = yaml.load(yaml_file, Loader=yaml.Loader)\n",
    "list_of_models = list(X.keys())\n",
    "print('\\n List of available models: \\n')\n",
    "for model in list_of_models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a model from above and run it on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Global_EXC_20Hz_smoothing200ms_causalkernel'\n",
    "\n",
    "cascade.download_model( model_name,verbose = 1)\n",
    "spike_rates = cascade.predict( model_name, traces )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrames for Ca2+ traces, CaImAn inferred spikes, CASCADE 100ms smoothing inferred spikes, and CASCADE 200ms inferred spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_traces_df = pd.DataFrame(np.array(cnm.estimates.C[cnm.estimates.idx_components]))\n",
    "caiman_s_df = pd.DataFrame(np.array(cnm.estimates.S[cnm.estimates.idx_components]))\n",
    "# cascade_s_df = pd.DataFrame(spike_rates)#[cnm.estimates.idx_components])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CaImAn ca_traces are on a much greater scale than CaImAn inferred spikes, so ca_traces_df can be divided by 100,000.<br>\n",
    "CASCADE DataFrames are filled with NaN values so they are replaced with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_traces_df = ca_traces_df / 1000000\n",
    "# cascade_s_df = cascade_s_df.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Ca2+ traces and compare CaImAn and CASCADE 100ms smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import random\n",
    "\n",
    "print(f\"There are {len(cnm.estimates.C)} total neurons. {len(cnm.estimates.idx_components)} of them are acceptable, while {len(cnm.estimates.idx_components_bad)} were rejected.\")\n",
    "neuron = random.randrange(len(cnm.estimates.idx_components))#int(input(f\"Pick a neuron from 0 to {len(cnm.estimates.idx_components)-1}\\n\\n****\\n\\n\"))\n",
    "  \n",
    "\n",
    "fig, axs = plt.subplots(2 , 1, figsize = (20,7.5))\n",
    "x = ca_traces_df.columns\n",
    "\n",
    "fig.suptitle(f\"Neuron {neuron} out of {len(cnm.estimates.idx_components)}\")\n",
    "\n",
    "axs[0].plot(ca_traces_df.loc[neuron], color='green')\n",
    "axs[0].set_title(\"Calcium Traces from CaImAn\")\n",
    "# axs[0 , 1].plot(ca_traces_df.loc[neuron], color='green')\n",
    "# axs[0 , 1].set_title(\"Calcium Traces from CaImAn\")\n",
    "\n",
    "\n",
    "axs[1].plot(caiman_s_df.loc[neuron], color = 'black')\n",
    "axs[1].set_title(\"Inferred Spikes (CaImAn)\")\n",
    "# axs[1 , 1].plot(cascade_s_df.loc[neuron], color = 'black')\n",
    "# axs[1 , 1].set_title(\"Inferred Spikes (CASCADE, causal 200ms smoothing)\")\n",
    "\n",
    "# axs[1 , 0].sharey(axs[1 , 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.now()\n",
    "\n",
    "ctime = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "if not os.path.exists(f\"{destination_dir}/{storage_folder}\"):\n",
    "    os.mkdir(f\"{destination_dir}/{storage_folder}\")\n",
    "    \n",
    "plt.savefig(f\"{destination_dir}/{storage_folder}/{fstem}_CA1_PLOT_causal_200ms_{ctime}.png\")\n",
    "# cascade_s_df.to_csv(f\"{destination_dir}/{storage_folder}/{fstem}_CascadeSpikes_{ctime}.csv\")\n",
    "# ca_traces_df.to_csv(f\"{destination_dir}/{storage_folder}/{fstem}_Traces_{ctime}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
